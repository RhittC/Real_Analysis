\documentclass[openany]{book}

\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,hyperref, multicol, tikz, romannum, wrapfig, graphicx, fontspec}
\usetikzlibrary{arrows.meta, positioning}
\usepackage[framemethod=tikz]{mdframed}
\usepackage[super]{nth}
\usepackage[backend=biber, style=alphabetic, sorting=ynt]{biblatex}

\addbibresource{tao_mywork.bib}


\newcounter{result}[section]
\setcounter{result}{0}



\newenvironment{result}[4]{
  \refstepcounter{result}

  \mdfsetup{
    frametitle={
      \tikz[baseline=(current bounding box.east),outer sep=0pt]
        \node[anchor=east,rectangle,fill=#4!20]
        {\strut #1~#2.\arabic{result}:~#3};
    },
    innertopmargin=10pt,
    linecolor=#4!20,
    linewidth=2pt,
    topline=true,
    frametitleaboveskip=\dimexpr-\ht\strutbox\relax
  }

  \begin{mdframed}\relax \begin{center}
}{
  \end{center} \hfill \end{mdframed} \vspace{3\baselineskip}
}

\hypersetup{colorlinks=True, linkcolor=teal}



\newcommand{\R}{\mathbb{R}}  
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}



\newcommand{\tr}{\mathcolor{teal}{\mathfrak{True}}}
\newcommand{\fa}{\mathcolor{purple}{\mathfrak{False}}}
\newcommand{\ill}{\mathcolor{orange}{\mathfrak{Ill}}}

\newfontfamily\myfont{Noto Sans Siddham Regular}
\newfontfamily\emoji{Segoe UI Emoji}
\newcommand{\order}[1]{{\myfont{\char"115A2}}$_{#1}$}

\newcommand{\myforall}{\kern.05em\ensuremath\forall\kern-.63em\rotatebox{110}{\rule{.73em}{.4pt}}}
\newcommand{\myforalll}{\ensuremath\forall\kern-.5em\forall}
\newcommand{\pred}[2]{#1\!\!\!\prec\!\!#2\!\!\succ}
\newcommand{\preddef}[2]{#1:\myforall_{\;#2}\rightsquigarrow \;\sqsubset\!\! \tr, \fa, \ill\!\!\sqsupset}

\newcommand{\ZF}{\mathcal{ZF}}

\newcommand{\suc}{\!+\!\!+\!}





\begin{document}
\pagenumbering{arabic}

\title{Tao Analysis - My Formulations, Visualisations and Proofs}
\author{Rhitt Chakravarty}
\date{January 2026}

\maketitle
\tableofcontents

\pagebreak

\setlength{\parskip}{8pt}
\chapter{Introduction}

\section{Abstract}

I decided to write this text as a means to consolidate my personal understanding of undergraduate Real Analysis, 
and also to practise the skill of writing academic papers with \LaTeX. 

It is heavily inspired and guided by Terrence Tao's Analysis Vol. \Romannum{1} and \Romannum{2} \cite{Tao}
However, I have taken many liberties in altering formulations to my liking, 
completely spelling out motivating arguments before most definitions and theorems (even if this greatly lengthens discussion), 
going on large digressions, and providing visuals.
A good portion of the text is also completely original content that arose from research and \textit{pause and ponder}\footnote{as suggested by Grant Sanderson, 3Blue1Brown} about specific curiosities as I progressed through Tao.
I've numbered these differently to preserve Tao's original chapter numbers.
Moreover, I'm including my solutions to the exercises in Tao's texts, and also made visuals and motivating arguments for them too where I saw fit, mainly for personal reference.

As a digression on expression, in aspiration of approbation from Big M's appellation upon examination, the language register is largely formal in an attempt to adhere to writing conventions. But we undergo register shifts towards 
informality where appropriate, particularly in avoiding the infamous passive voice\footnote{why is this even a scientific convention smh ts pmo}. This is because it would unnecessarily restrict syntactic freedom 
in a situational context where it is the \textit{content} that matters far more than the expression. Thus, it is more favourable to be able to convey the content precisely and elegantly without jumping though linguistic hoops every step of the way.


\section{Why do Analysis?}

\subsection{Motivation 1}

The most obvious reason to do Analysis is to understand deeper concepts that stray far from the base intuition you get from VCE and high school in general.
For example, you may have heard the result that there are more $x\in\R$ with $x\in(0, 1)$ than there are $p\in\Q$ with $p\in(-\infty, \infty)$\footnote{the precise statement is with a concept called \textit{cardinality}}.
Your intuition tells you this is absurd, because clearly both are infinite! How can we have $\infty_1>\infty_2$? And even if we could, \textit{surely} you can't squeeze in more reals between $0$ and $1$ than rationals in the entire number line. 
Even more counterintuitive is that there are \textit{just as many} $n\in\N$ as there are $x\in\Z$, even though clearly for every $n\in\N$ there are both $x=\pm n\in\Z$,
and so you'd expect there to be about twice as many integers as there are naturals.
It seems like mathematicians are just making stuff up at this point.
But in Real Analysis, we handle $\infty$ \textit{rigorously} to make such statements not only meaningful, but to fully understand the motivation for even discussing such matters in the first place.
The full level of rigour makes many theorems feel discoverable, in that you properly understand how you would derive and prove them in the first place.

We will see how Real Analysis answers exactly what you can and can't do with $\infty$. E.g. Consider the matrix 
$$ M = \begin{pmatrix}
    1   & 0     & 0           & \cdots \\
    -1  & 1     & 0           & \cdots \\
    0   & -1    & 1           & \cdots \\
    0   & 0     & -1          & \cdots \\
    \cdots & \cdots  & \cdots & \ddots
\end{pmatrix} $$
You'd expect the sum of all elements $\sum M_{ij}$ to be the same either way, whether you sum over rows or over columns first.
But we have, if you'll excuse the lax notation, $$\sum_{\text{over rows first}} M = \sum_{\text{over columns}} \begin{pmatrix}1\\0\\0\\\vdots\end{pmatrix}=1,\qquad \sum_{\text{over columns first}} M = \sum_{\text{over rows}} \begin{pmatrix}0 & 0 & 0 & \cdots \end{pmatrix}=0$$
$$\therefore \left(\sum_{\text{over rows first}} M \quad=\quad1\right)\quad\neq\quad\left(\sum_{\text{over columns first}} M\quad =\quad0\right)$$

So we have illustrated that you can't always interchange the order in which you sum infinitely many numbers, contrary to intuition.
Real Analysis gives the full derivation for the precise conditions in which you can safely do so\footnote{see Fubini}.
In general, it teaches you how to properly deal with $\infty$ in all its mischievous antics.
So in a sense, Real Analysis can make you like \textit{The Man Who Knew Infinity } {\emoji{ðŸ¥¶ðŸ¥¶ðŸ¥¶}}.

More than that, Real Analysis answers to the highest echelon that is possible with logic (provably so, in fact) the \textit{why} behind essentially everything you've ever been taught in maths from kindergarten to high school, leave some small details about $\mathbb{C}$.
You realise the true degree of freedom you actually have in maths.
And you learn complete objectivity.
You don't have to take anyone's word for it, just prove it yourself.
You learn to make a statement, and the proof of it, so damn precise that there is \textit{zero} ambiguity or subjectivity in it; and I say this without hyperbole.
Doesn't matter if your English teacher thinks your expression is lacking; you can be \textit{absolutely sure} that your proof is correct.
And perhaps most importantly, if you don't like standard definitions or formulations, you can just make your \textit{own} - full independence.

\subsubsection{Motivation 2 (very important)}

We now motivate rigour as an absolute necessity in maths as a whole.
We will see how blindly following the whims of what our intuition deems reasonable can very easily lead to contradiction. 
The many times this occurred historically, there was great philosophical anguish on what assumptions to keep and what to discard, substantially impeding on mathematical progress every single time. 

\begin{wrapfigure}{r}{0.1\textwidth} \centering \begin{tikzpicture}
    \draw[cyan, thick] (0, 0) -- node[midway, below] {$1$} (1, 0);
    \draw[cyan, thick] (1, 0) -- node[midway, right] {$1$} (1, 1);
    \draw[magenta, thick] (1, 1) -- node[midway, left=5pt, above] {$\sqrt{2}$} (0, 0);
\end{tikzpicture} \end{wrapfigure}
For example, take $\sqrt{2}$, a quantity that arises in geometry very naturally as the length of the hypotenuse in a triangle with both other side lengths $1$.
In ancient Greece, many held the worldview that everything in the real world, like this hypotenuse, can be quantified as a rational number in $\Q$.
And they held this assumption to be so blatantly obvious that it underpinned their philosophy of everything from music to the universe itself.
So when it was found that $\sqrt{2}\in\Q$ is contradictory, even though the triangle very much exists, it led to a crisis in which many ancient Greeks had to reevaluate their entire philosophy.

Because we've been taught from a young age that irrational numbers exist and do indeed show up in the real world, we now find the concept to be no doubt very intuitive. 
But how can we be absolute \textit{sure} there isn't some other cancerous contradiction hiding somewhere in our mathematical foundations as well, just waiting to spread into everything we think we know, as it did for the Greeks?
The truth is, we're \textit{not} sure. And it's in fact been \textit{proven}\footnote{see Kurt G\"odel's Incompleteness Theorem 2 (on consistency)} that we we can never be sure. 
Not unless we weaken those foundations so much that we don't even have enough complexity for \textit{primary school level arithmetic}, which would be very absurd. So as we shall see, we do the next best thing: 
minimise our collection of assumptions to the bare minimum that is still feasible.

To be clear, the issue we mention isn't with logic itself. As a rather lengthy aside, the question of whether logic is valid is philosophical in nature, and seemingly can't ever have a definitive resolution.
For example, it could very well be the case that we and our fictitious universe only exist in the vivid yet incoherent dream of a dolphin. If so, logic as we perceive it only \textit{appears} valid to us,
yet completely flawed and contradictory to a scientist observing the dream from outside in the \textit{real} universe.
But even though pondering over such hypotheticals about reality itself may be interesting, 
doubting logic every step of the way puts overly restrictive bounds on what mathematical progress is possible.
A mathematician needs to be able to say ``if $P$ is $\tr$ and $P$ implies $Q$, then $Q$ is also $\tr$'' without a second thought.
So they leave those deep questions for the philosopher to concern themself with, and instead take the validity of logic to be given.

More specifically, the mathematician prescribes a list of objective and reasonable rules for how logic operates that they consider fundamental, independent of whatever content (in our case, maths) you choose to discuss with it, and hands it over for the philosopher to contest.
Having set in stone the interface between logic and maths, the mathematician now gives themselves the freedom to question \textit{anything} in the realm of maths using proofs that adhere to the formal logical rules,
but they have so much confidence in those fundamental logical rules themselves that they never doubt them again.
This way, the mathematician is sure that everything they conclude is as valid as logic itself (with some caveats that are discussed now), and they're content with that.
We will see an explicit formalism of logic next subchapter.


%To be clear, the issue isn't with logic itself. As a rather lengthy aside, the question of whether logic is valid is philosophical in nature, and seemingly can't ever have a definitive resolution.
%For example, it could very well be the case that we and our fictitious universe only exist in the incoherent dream of a butterfly. If so, logic as we perceive it only \textit{appears} valid to us,
%yet completely wrong to a scientist observing the dream from outside in the real world. But even though such fundamental questions about reality may be interesting, 
%doubting logic every step of the way puts overly restrictive bounds on what mathematical progress is possible.
%So they're for the philosopher to ponder over. Instead, the mathematician prescribes a handful of intuitive operations on True/False valued statements, which formalise pure logic. E.g.
%\begin{align*} &\text{(True }\&\text{ True) is True, but} \\ &\text{(True }\&\text{ False) is False, as True and False are said to contradict each other.} \end{align*}
%Then they prescribe a few more rules on how to produce those logical statements from free variables (which can be mathematical objects), completing the formal, objective link from logic to maths.
%E.g.
%\begin{align*} ((\forall x)\; x\text{ is a gorilla})\implies \text{ Harambe is a gorilla}\text{) is True} \end{align*}
%Finally, they combine all of this into a rulebook which they call the formal logic. Confident that the logic reflects reality, they hand it over to the philosopher to question the validity of.
%The mathematician is now happy to accept their logic as absolute and instead ponders questions about how the logic actually affects mathematical statements (theorems, lemmas, corollaries, etc.). 
%And even if the philosopher someday finds that the logic is only valid in the dream of a butterfly and invalid outside of it, much of the work done by mathematicians could very well still be moulded to adhere to whatever rulebook is followed by the world outside the dream.
%
%Now that we have set our logic in stone, how do we proceed?
%Logic can only tell us about the relationships between logical statements, but makes no comment about many individual statements involving free variables.
%E.g. we can show $$\text{(I am a lazy person \& all lazy people are monkeys)}\implies\text{(I am a monkey)}\footnote{given this is stated in a way that avoids mentioning sets}$$
%as a whole is True directly from our logic\footnote{see vacuous truth in the next subchapter}, but we can't individually show that (I am a lazy person) or (all lazy people are monkeys) are True with logic alone because of the free variables (I), (lazy person/people) and (monkey(s)).
%And if either of those two statements turn out to be False, then we have no information about whether (I am a monkey) is True or False. I could very well be a monkey despite not being lazy. Thus, all in all, we have an ($\implies$) statement that is True but we can't show definitively that its implication (I am a monkey) is also True\dots which is a good thing because I'm pretty confident I'm not a monkey (but can I \textit{show} definitively that I'm not? Once again, no). 
%
%This is a necessary tradeoff we made so the mathematician will never have to doubt this barebone logic.

Note, logic is so barebone, as it should be if the mathematician is to never doubt it, that it makes no comment about what is definitively true about the individual objects it operates on.
The only thing it can judge is the relationship between our assumptions and other statements, both of which concern those objects.
E.g. we may not be able to assert whether (I am a monkey) is definitively $\tr$ or $\fa$ with pure logic alone, but we \textit{can} say that under the assumptions
(I am lazy) and (all who are lazy are monkeys), I am indeed a monkey. Under different, perhaps more sensible assumptions though, maybe I'm not a monkey...which is a good thing because I'm pretty confident I'm not a monkey (but can I \textit{prove} it definitively? No!)

We call our assumptions in mathematics our \textit{axioms}. 
And as alluded to before, mathematicians of the early \nth{20} century sought a minimal collection of axioms that we \textit{know} don't suffer the same fate as the ancient Greeks.
But alas, it was too good to be true.
It was soon proven with pure logic that the only such collections we can be sure have no contradictions are far too weak to be of much value to us.
This will be explored in some more depth in Chapter $3$, on Hilbert's Program (consistency).

As a concluding remark, we do not deny the value of intuition. In fact, intuition is absolutely essential for \textit{developing} a conjecture and motivating why it might be plausible. 
Without it we are stuck running a fool's errand of perpetual guess and check, never able to come up with something original and insightful.
But once we are confident that our conjecture is indeed plausible, we \textit{need} to follow a rigorous standard of proof independent of intuition.
It's the best way we know of to minimise the risk as much as feasible
for a contradiction to sneak up on us from a single far-reaching result we prematurely took as granted long ago. 
That would shatter the foundations of mathematics, much like the contradictory assumption $\sqrt{2}\in\Q$ did for the Greeks. 
Of course, in perhaps the saddest result of modern maths, we've shown logically that we still can't ever completely eliminate the risk.
But nonetheless, mathematicians collectively agree on a handful of axioms called $\ZF$\footnote{there is another axiom called Choice we will explore in Chapter 8 that together with $\ZF$ forms $\ZF \mathcal{C}$, a slightly weaker standard of proof, but we will see that it is in many respects equivalent to $\ZF$ for our purposes} defining ``sets'' (all of which we will encounter in the next 2 chapters) as the basis for our gold standard of proof, 
which is loosely considered our best bet to avoid contradictions. Hence:
\begin{result}{Definition}{G}{The Gold Standard of Proof}{green}
    A conjecture $P$ is considered plausible enough to be called ``proven'' \textit{if and only if} we can show with our logic that:

    (Assuming $\ZF$, we have $P$ is $\tr$) as a whole is $\tr$

    To distinguish, we sometimes say $P$ is ``definitively proven'' \textit{if and only if} we can show that:

    ($P$ is $\tr$) without need for assumptions
\end{result}

.

\section{Logic Preliminaries}

\subsection{Statements - Pure Logical Operations}


First, we define statements as entities in logic that each take on exactly one of the truth values $\tr$, $\fa$ or $\ill$.
Informally, the latter stands for \textit{ill-formed} statements like $\frac{1}{0} = 1$, modelling what is sometimes called \textit{no truth value}.
By default, statements are assigned $\ill$ unless we explicitly prescribe a method of obtaining its truth value.

There are certain operations we should define on statements to enrich our logic.
Given a statement, we want to be able to talk of the opposite (the \textit{negation}) of it.
And given several statements, we want to be able to combine them 

\subsection{0th Order Objects and 1st Order Logic - Link with Maths}
\subsection{Restricted 2nd Order Logic - Schema}


Define a statement as a logical entity that takes on either $\tr$ (True), $\fa$ (False) or $ \ill$ (Ill-Formed),
where $\ill$ indicates the statement is left undefined and considered to have no truth value (e.g. $\frac{1}{0}=1$). 
This way, we have a mechanism to handle ill-formed statements in case they slip through our fingers somewhere down the line.

Also note that by default we define ($S_1 \implies S_2$) to be $\tr$ whenever $S_1$ has a truth value other than $\tr$. This is known as vacuous truth.
The motivation is simply that it makes things easier to show. 
Under this definition, if we want to show that ($S_1\implies S_2$) as a whole is $\tr$,
 all we need to do is consider the case where $S_1$ is $\tr$ and follow logical arguments that lead to $S_2$'s truth. 
 There is no need to consider when $S_1$ is $\fa$ or $\ill$, making arguments significantly less cluttered.
If you do not agree with vacuous truth, you can of course define ($\implies$) otherwise, but you will soon realise how unnecessarily messy every single proof becomes.

Furthermore, an ($\implies$) statement only comments about \textit{correlation}, not \textit{causation}.
 So you could satisfy (pigs can fly $\implies$ the stock market will crash in $2142$) if pigs can't fly or if somehow both are true, even if there's no causal link between the two individual statements (I doubt flying pigs alone would cause the stock market to crash).
 This is because causality can be an exceedingly philosophically subjective concept (do I think because I am or am I because I think?), and so logic doesn't concern itself with it.
 Note that we don't mean causality in the relativistic sense, which would be a completely different concept.

\begin{result}{Definition}{L}{Operations on Statements}{green}
    Given a statement $S$, the new statement ($not S$) can be formed as follows:
    
    \begin{tabular}{c | c}
        $S$ & $notS$ \\ \hline
        $\tr$ & $\fa$ \\ 
        $\fa$ & $\tr$ \\ 
        $\ill$ & $\ill$
    \end{tabular}
    
    
    Given two statements $A$ and $B$, new statements ($S_1\&S_2$) and ($S_1\implies S_2$) can be formed as follows:

    \begin{tabular}{c c | c | c}
        $S_1$ & $S_2$
        & $S_1 \& S_2$
        & $S_1 \implies S_2$ \\ \hline

        $\tr$ & $\tr$
        & $\tr$ & $\tr$ \\

        $\tr$ & $\fa$
        & $\fa$ & $\fa$ \\ \hline

        $\fa$ & $\tr$
        & $\fa$ & $\tr$ \\

        $\fa$ & $\fa$
        & $\fa$ & $\tr$ \\ \hline

        $\tr$ & $\ill$
        & $\ill$ & $\ill$ \\

        $\ill$ & $\tr$
        & $\ill$ & $\tr$ \\ \hline

        $\fa$ & $\ill$
        & $\ill$ & $\tr$ \\

        $\ill$ & $\fa$
        & $\ill$ & $\tr$ \\ \hline

        $\ill$ & $\ill$
        & $\ill$ & $\tr$
    \end{tabular}


    Given two statements $S_1$ and $S_2$, new statements ($S_1orS_2$), ($S_1\impliedby S_2$), ($S_1 \iff S_2$) can be formed as follows:
    
    $\begin{aligned}
        (S_1 or S_2) & \text{ has the same truth value as } (not(not S_1\;\; \&\;\; not S_2)) \\
        (S_1 \impliedby S_2 ) & \text{ has the same truth value as } (S_1 \implies S_2) \\ 
        (S_1 \iff S_2 ) & \text{ has the same truth value as } ((S_1 \impliedby S_2 ) \;\;\&\;\; (S_1 \implies S_2))
    \end{aligned}$

\end{result}


\pagebreak
We now discuss how to link our logic to various free variables in a way that avoids circular reasoning and self-referential paradoxes.

Firstly, we refer to our most basic mathematical objects as \textit{$0$th-order objects}. 
$0$-th order objects are not themselves in terms of 

Predicates are primitive analogues of functions. 
That is, they can be thought of as like functions with domain being all zero-order objects and range being the truth values.
Suggestively, we denote:
$$\preddef{P}{0}$$
The biggest difference being that they do not actually relate a domain set to a codomain set.
This is because logic itself is used to define sets and so this would be very blatantly circular.

\order{0 test}

Instead, 


We now define how to produce statements from free variables using \textit{quantifiers}:


\begin{result}{Definition}{L}{Quantifiers}{green}
   $$\exists, \forall, \pred{P}{n}$$ 

\end{result}



\pagebreak
\chapter{Construction of Naturals}

\setcounter{subsection}{-1}
\section{Peano Axioms - Motivation for Defining Naturals Axiomatically}
We first motivate the set of naturals $\N = \{0, 1, 2, \dots\}$ to be so essential that it deserves its own few axioms.

As mentioned, $\ZF$, the ultimate handful of axioms we are leading up to, lay out what is legally a set. So what even is a set intuitively? Informally, a set $S$ is the collection of all objects $x$ satisfying a certain predicate\footnote{see 1.4 Logic Preliminaries} $\preddef{P}{0}$. That is,
$$ x \in S \iff \pred{P}{x}$$
In fact, if we could take that informal definition for all $P$ as our axiom, then we'd basically be done! That alone would imply 7 out of 8 $\ZF$ Axioms.
But alas, it's too good to be true. We'll see in the next chapter that such an axiom would allow for certain infinitely large sets that lead to contradictions.
But the resolution isn't to completely reject the notion of $\infty$ itself, as we still very much need it to derive many rich and powerful results everywhere from number theory to calculus and beyond.
So instead, we handle $\infty$ very subtly.

The most basic form of $\infty$ is that of ``counting numbers'', which we will formalise into the set $\N = \{0, 1, 2, \dots\}$. Informally speaking, is there a counting number out there that you can't count past?
No! You've no doubt had fun with this as a child. You compete with your friend to see who can think up the biggest number imaginable. Whatever $n$ they think up, you respond swiftly with $n+1$.
This is a property we want for our $\N$, that it doesn't have a maximal element; you can always find a larger one. Infinity in the sense of that property doesn't seem to be contradictory, so we define our $\ZF$ axioms to allow for such an $\N$ to exist.
We will see throughout the text that all other infinite sets such as $\Z, \Q, \R$, and subsequently all other notions of $\infty$, can be constructed directly from $\N$, so we are happy.

We will later see that one of the $\ZF$ Axioms makes reference to all 5 Peano Axioms, but the converse is not true. So we say $\ZF$ contains Peano.
The standard in the literature is actually to not even mention the Peano Axioms at all, but instead condense them into a single, concise axiom in $\ZF$ that satisfies our formulation of Peano \textit{automatically}.
We will not do this, as it is far more intuitive to define Peano first.

\section{Peano Axioms - Formulation}
We now lay out the requirements that our first infinite ``set'' $\N$ must satisfy as the 5 Peano Axioms. 
As sets have not yet been defined, we primitively let $\N[n]$ be the predicate for whether $n$ is natural, 
substituting for where we would otherwise say $n \in \N$. We abbreviate ($\forall n\;s.t.\; \N[n]$) as ($\forall \N[n]$)


    We start with the bare minimum by demanding that some fixed object, namely $0$, be well defined. $0$ will be crucial to defining a few later axioms, as it gives us a sort of starting point.

    \begin{result}{Axiom}{P}{Existence of 0}{red}

        There exists an object $0$ that is natural and can be used in later axioms.
        $$\exists0\quad s.t.\quad \N[0]\quad\&\quad \text{\textcolor{magenta}{P.3} and \textcolor{magenta}{P.5} are met.}$$

        \begin{tikzpicture}[scale=1.2]
            \fill[cyan] (0,0) circle (3pt);
            \draw[ultra thick, cyan] (0,-0.2) -- (0, 0.2);
            \node[below, cyan, font=\large] at (0,-0.2) {$0$};
        \end{tikzpicture}

    \end{result}

    \pagebreak

    Now to populate $\N$, we introduce a new primitive operation (which similarly is not truly an operation - it is no more than a suggestive notation for objects otherwise unrelated to $0$) that will later by superseded by addition. We call it \textit{succession}, and it satisfies an axiom of closure as follows.
    It is named closure since you can't ``escape'' the naturals (you are en\textit{closed} in naturals) no matter how many times you take the succession.
    Informally, we hope that it behaves like our intuition for incrementing a number by $1$, and thus forces the infinitely many ``counting numbers" to now be well defined and in $\N$.
    Denote the succession of a natural $n$ as $n\suc$, and label $(1:=0\suc),\; (2:=1\suc),\; (3:=2\suc),\;\dots$


    \begin{result}{Axiom}{P}{Closure of $\N$ under $(\suc)$}{red}
        All naturals have natural successions.
        $$(\forall \N[n]) \quad \N[n\suc]$$

        \begin{tikzpicture}[scale=1.2]

            \draw[->] (0,0) -- (5.5, 0);
            \fill[cyan] (0,0) circle (3pt);
            \draw[ultra thick, cyan] (0,-0.2) -- (0, 0.2);
            \node[below, cyan, font=\large] at (0,-0.2) {$0$};

            \fill[magenta] (1,0) circle (3pt);
            \draw[ultra thick, magenta] (1,-0.2) -- (1, 0.2);
            \node[below, magenta, font=\large] at (1,-0.2) {$1$};
            \draw[->, ultra thick] (0,0) to[bend left=90] node[pos=0.5, sloped, above] {$0\suc$} (1,0);

            \fill[magenta] (2,0) circle (3pt);
            \draw[ultra thick, magenta] (2,-0.2) -- (2, 0.2);
            \node[below, magenta, font=\large] at (2,-0.2) {$2$};
            \draw[->, ultra thick] (1,0) to[bend left=90] node[pos=0.5, sloped, above] {$1\suc$} (2,0);

            \fill[magenta] (3,0) circle (3pt);
            \draw[ultra thick, magenta] (3,-0.2) -- (3, 0.2);
            \node[below, magenta, font=\large] at (3,-0.2) {$3$};
            \draw[->, ultra thick] (2,0) to[bend left=90] node[pos=0.5, sloped, above] {$2\suc$} (3,0);

            \fill[magenta] (4,0) circle (3pt);
            \draw[ultra thick, magenta] (4,-0.2) -- (4, 0.2);
            \node[below, magenta, font=\large] at (4,-0.2) {$4$};
            \draw[->, ultra thick] (3,0) to[bend left=90] node[pos=0.5, sloped, above] {$3\suc$} (4,0);

            \draw[->, ultra thick] (4,0) to[bend left=90] node[pos=0.5, sloped, above] {$4\suc$} (5,0);

        \end{tikzpicture}
    \end{result}

    

    However, \textcolor{magenta}{P.1} and \textcolor{magenta}{P.2} alone are not strong enough to force $\N$ to populate with our infinitely many elements.
    In particular, they do not prevent existence of a natural $n$ with $(n\suc)=0$.
    And yet, informally speaking, this means $n$ overflows back to $0$, forming what's called a modulo cycle. As illustrated below (with $n=4$), this only guarantees the existence of $n+1$ naturals. 
    Modulo sets have many applications, but they are not what we desire as a full, infinite set of ``counting numbers'', particularly if that $n$ turns out to be $0$ itself, leading to $0$ trivially being the only guaranteed natural.
    So we explicitly force $\N$ to not be such a modulo cycle by demanding that a natural's succession never overflows back to $0$.

    \begin{result}{Axiom}{P}{$\N$ does not have a modulo cycle overflowing to $0$}{red}
        No natural's succession can be $0$.
        $$(\forall \N[n])\quad (n\suc) \neq 0$$


        \begin{tikzpicture}[scale=1.2, every node/.style={font=\large, inner sep=1pt}]
            \def\n{5}
            \def\radius{1}

            \foreach \i in {0,...,4} {
                \pgfmathsetmacro{\angle}{90-\i*360/\n}
                \coordinate (N\i) at (\angle:\radius);
                \fill[magenta] (N\i) circle (3pt);
            }
            \fill[cyan] (N0) circle (3pt);

            \draw[ultra thick, cyan] (N0 |- 0,0.75) -- (N0 |- 0,1.25);

            \node[above=10pt, cyan, font=\Large] at (N0) {$0$};
            \node[right=10pt, magenta, font=\Large] at (N1) {$1$};
            \node[below=10pt, magenta, font=\Large] at (N2) {$2$};
            \node[below=10pt, magenta, font=\Large] at (N3) {$3$};
            \node[left=10pt, magenta, font=\Large] at (N4) {$4$};

            \draw[->, ultra thick] (N0) to[bend left=30] node[midway, right, outer sep = 1mm, font=\small] {$0\suc$} (N1);
            \draw[->, ultra thick] (N1) to[bend left=30] node[midway, right, outer sep = 1mm, font=\small] {$1\suc$} (N2);
            \draw[->, ultra thick] (N2) to[bend left=30] node[midway, below, outer sep = 1mm, font=\small] {$2\suc$} (N3);
            \draw[->, ultra thick] (N3) to[bend left=30] node[midway, left, outer sep = 1mm, font=\small] {$3\suc$} (N4);
            \draw[->, ultra thick] (N4) to[bend left=30] node[midway, left, outer sep = 1mm, font=\small] {$4\suc$} (N0);
        \end{tikzpicture}

    \end{result}


    \pagebreak
    As it stands, the issue hasn't been fully resolved yet.
    There is still the pathological case of an \textit{offset} modulo cycle, in which a natural $n$ overflows back so that $(n\suc)=(m\suc)$ even though $(m\suc)$ is already the successor of a different natural $m$.
    An offset modulo cycle once again guarantees only finitely many naturals, which we don't want.
    We now complete our requirements on $(\suc)$ by demanding no such successions are the same. Informally, we make $(\suc)$ \textit{injective} i.e. a one-to-one operation (function).


    \begin{result}{Axiom}{P}{$\N$ has no otherwise offset modulo cycles either}{red}

        Succession is injective (one-to-one). That is, distinct naturals have distinct successions.
        $$(\forall \N[n], \N[m])\quad n \neq m \implies (n\suc) \neq (m\suc)$$

        \begin{tikzpicture}[scale=1.2, every node/.style={font=\large, inner sep=1pt}]
            
            \def\n{5}
            \def\radius{1}

            \foreach \i in {0,...,4} {
                \pgfmathsetmacro{\angle}{90-\i*360/\n}
                \coordinate (N\i) at (\angle:\radius);
                \fill[magenta] (N\i) circle (3pt);
            }
            \fill[cyan] (-2, 0 |- N0) circle (3pt);
            \draw[ultra thick, cyan] (-2,0.75) -- (-2,1.25);


            \node[above=10pt, cyan, font=\Large] at (-2, 0 |- N0) {$0$};
            \node[above=10pt, magenta, font=\Large] at (N0) {$1$};
            \node[right=10pt, magenta, font=\Large] at (N1) {$2$};
            \node[below=10pt, magenta, font=\Large] at (N2) {$3$};
            \node[below=10pt, magenta, font=\Large] at (N3) {$4$};
            \node[left=10pt, magenta, font=\Large] at (N4) {$5$};

            \draw[->, ultra thick] (-2, 0 |- N0) to node[midway, above, outer sep = 1mm, font=\small] {$0\suc$} (N0);
            \draw[->, ultra thick] (N0) to[bend left=30] node[midway, right, outer sep = 1mm, font=\small] {$1\suc$} (N1);
            \draw[->, ultra thick] (N1) to[bend left=30] node[midway, right, outer sep = 1mm, font=\small] {$2\suc$} (N2);
            \draw[->, ultra thick] (N2) to[bend left=30] node[midway, below, outer sep = 1mm, font=\small] {$3\suc$} (N3);
            \draw[->, ultra thick] (N3) to[bend left=30] node[midway, left, outer sep = 1mm, font=\small] {$4\suc$} (N4);
            \draw[->, ultra thick] (N4) to[bend left=30] node[midway, left, outer sep = 1mm, font=\small] {$5\suc$} (N0);
        \end{tikzpicture}


    \end{result}


    We now lay out by far the most useful Peano Axiom, which lets us handle the sheer infinite size of $\N$ recursively.
    It is induction, which makes intuitive sense with a domino analogy. 
    Note, induction is not a full logical axiom, as it makes reference to predicates as free variables, which is strictly speaking illegal. 
    This is why it's called an Axiom Schema instead when you want to be logically precise.
    Indeed, it is logically consistent if you consider it to be no more than a template for generating individual axioms for every predicate you need as you go, all of which are themselves well formed logical statements.

    \begin{result}{Axiom Schema}{P}{(PMI) Principle of Mathematical Induction}{red}
    
        If a predicate is met for $0$ (Base Case), and it being satisfied for some natural implies it's met for the succession as well (Inductive Case), then as a domino effect, the predicate is met for all naturals.

        \hfill

        $(\forall P:\rightsquigarrow \{\tr, \fa, \ill\})\qquad(P[0]\;\;\;\&\;\;\;((\forall \N[k])\;P[k]\!\!\implies\!\!P[k\suc])) \quad \implies \quad (\forall \N[n])\; P[n]$

        \vspace{2\baselineskip}

        \begin{tikzpicture}[
            dom/.style={rectangle, draw, rotate=-20, minimum width=0.4cm, minimum height=1.2cm, thick},
            arrow/.style={->, thick}
        ]

            \node[dom, cyan] (D1) at (0,0) {};
            \node[below=18pt, cyan] at (D1) {$P(0)$};

            \node[dom, magenta] (D2) at (3,0) {};
            \node[below=18pt, magenta] at (D2) {$P(1)$};

            \node[dom, magenta] (D3) at (6,0) {};
            \node[below=18pt, magenta] at (D3) {$P(2)$};

            \node[below=18pt, magenta] at (9.3, 0) {$P(n)$};


            \draw[arrow] (D1.east) -- node[midway, above, font=\small] {$P(0)\!\!\implies\!\!P(1)$} (D2.west);
            \draw[arrow] (D2.east) -- node[midway, above, font=\small] {$P(1)\!\!\implies\!\!P(2)$} (D3.west);
            \draw[arrow] (D3.east) -- node[midway, above, font=\small] {$P(k)\!\!\implies\!\!P(k\suc)$} (9, 0) node[magenta, right] {$\cdots$};

        \end{tikzpicture}

    \end{result}

    \pagebreak

    We now briefly discuss implications for after $\ZF$ will be well defined. Abstractly speaking, all sets $X$ equipped with an analogous operation $S: X\to X$ (refered to together as an algebraic structure $\langle X, S\rangle$), that obeys the 5 Peano Axioms is said to be \textit{isomorphic} with $\langle\N, (\suc)\rangle$, denoted $\langle X, S\rangle\cong\langle\N, (\suc)\rangle$.
    Note that due to our later discussions only relying on logical implications from the axioms, which are met by $\langle X, S\rangle$, the results we derive must apply to every such isomorphism $\langle X, S\rangle$, given we rewrite our definitions accordingly.
    As such, we do not strictly define a particular $\langle \N, (\suc)\rangle$, but rather refer abstractly to any such solution $\langle X, S\rangle$ to Peano.

    So in a sense, the Peano Axioms lay out a kind of citizenship test, in which $\langle X, S\rangle$ is considered a natural structure if and only if it passes, and it gets all the perks of being a natural citizen that we will now derive.

    \section{Addition}
    \section{Multiplication}



    \chapter{ZF Set Theory}
    \setcounter{section}{1}
    \section{Naive Set Theory Axioms - Too Good to be True}
    \setcounter{section}{0}
    \section{ZF Axioms}
    \setcounter{section}{2}
    \section{Functions}
    \section{Images}
    \section{Cartesian Products}
    \section{Cardinality}
    \section{Hilbert's Program}


    \chapter{Constructing Integers and Rationals}
    \section{Constructing Integers - Subtractive Closure of Naturals}
    \section{Constructing Rationals - Divisive Closure of Integers}
    \section{Exponentiation of Rationals to Integer Powers and the Modulus}
    \section{Why Rationals are Inadequate - Motivation for Reals}

    
    \chapter{Constructing Reals - Cauchy Completion of Rationals - The (Almost) Perfect Field}
    \setcounter{section}{-1}
    \section{Aside - Dedekind Construction of Reals}
    \section{Cauchy Sequences}
    \section{Defining Equivalence of Cauchy Sequences}
    \section{Cauchy Construction of Reals}
    \section{Defining an Order on Reals}
    \section{Least Upper Bound Property (LUBP) - Fixing the Problems of Rationals}
    \section{Exponentiation of Reals to Rational Powers}


    \chapter{Limits of Sequences}
    \section{Convergence and Limit Laws}
    \section{Defining Extended Reals}
    \section{Suprema and Infima}
    \section{Limsup, Liminf and Limit Points}
    \section{Some Standard Limits}
    \section{Subsequences}
    \section{As Far as Exponentiation of Reals Goes - Inadequacies of Reals}

    \chapter{Series}
    \section{Finite Series}
    \section{Infinite Series}
    \section{Series on Nonnegative Terms}
    \section{The Problem with Rearranging Series}
    \section{Root and Ratio Tests}
    
    \chapter{Handling Infinity}
    \section{Countable Cardinality}
    \section{Summation on Infinite Sets}    
    \section{Uncountable Cardinality}
    \section{Axiom of Choice}
    \section{Well-Ordering of Uncountable Sets}


    \chapter{Continuity}
    \section{Subsets of Reals}
    \section{Algebra on Real Valued Functions}
    \section{Limiting Values of Functions}
    \section{Continuous Functions}
    \section{Left and Right Limits}
    \section{The Max Principle}
    \section{The Intermediate Value Theorem (IVT)}
    \section{Monotonicity}
    \section{Uniform Continuity}
    \section{Limits at Infinities}

    
    \chapter{Differentiation}


    \chapter{Riemann Integral}


    \chapter{Metric Spaces}


    \chapter{Generalising Continuity to Metric Spaces}

    
    \chapter{Uniform Convergence}


    \chapter{Power Series}


    \chapter{Fourier Series}


    \chapter{Multivariable Differential Calc}

    
    \chapter{Lebesgue Measure - oooh}


    \chapter{Lebesgue Integration}

    \appendix
    \chapter{List of Non-Standard Notations Used}

    In rough order of appearance:

    $\tr, \fa, \ill$ are the truth values True, False and Ill-formed respectively. We use a formulation of 3-valued logic to handle ill-formed and undefined statements using $\ill$.

    $\preddef{P}{0}$ is a predicate, i.e. a primitive version of a function whose input is any mathematical object (not possible with functions) and output is a truth value.

    $\pred{P}{x}$ is the outputted truth value of the predicate $P$ when inputted the object $x$

    $\langle x_1, x_2, \dots, x_n \rangle$ is an $n$-tuple


    \printbibliography[heading=bibintoc, title={Bibliography}]


\end{document}



